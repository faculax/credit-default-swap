# Test Evidence Framework# Test Evidence Framework



**Unified test evidence generation, validation, and reporting for the CDS Platform**AI-assisted, story-driven test and evidence framework for the CDS Platform.



## ğŸ¯ Overview## Overview



The Test Evidence Framework is a comprehensive TypeScript toolkit that bridges user stories, test execution, and evidence reporting. It automates the generation of tests from story requirements, validates implementation completeness, and provides unified evidence dashboards across all services.This framework automates test generation from user stories across all services (frontend, backend, gateway, risk-engine), pushing evidence to ReportPortal and generating unified test coverage reports.



### Key Capabilities## Architecture



- **Story-Driven Testing**: Parses user story markdown to generate test plans and scaffolding```

- **Multi-Service Support**: Backend (Spring Boot/Java), Frontend (React/TypeScript), Gateway, Risk Enginetest-evidence-framework/

- **Flow Testing**: End-to-end integration tests across service boundariesâ”œâ”€â”€ src/

- **ReportPortal Integration**: Automated test result uploads with story traceabilityâ”‚   â”œâ”€â”€ models/              # TypeScript type definitions

- **Evidence Export**: Static HTML dashboards showing coverage and test execution historyâ”‚   â”‚   â”œâ”€â”€ story-model.ts   # Story parsing types

- **CI/CD Ready**: GitHub Actions workflows with selective execution and automated reportingâ”‚   â”‚   â””â”€â”€ test-plan-model.ts # Test planning types

â”‚   â”œâ”€â”€ parser/              # Story markdown parser

## ğŸ— Architectureâ”‚   â”‚   â””â”€â”€ story-parser.ts

â”‚   â”œâ”€â”€ catalog/             # In-memory stores

```â”‚   â”‚   â”œâ”€â”€ story-catalog.ts

test-evidence-framework/â”‚   â”‚   â””â”€â”€ test-plan-catalog.ts

â”œâ”€â”€ src/â”‚   â”œâ”€â”€ planner/             # Test planning engine

â”‚   â”œâ”€â”€ parser/              # Story markdown parsing (Story 20.1)â”‚   â”‚   â””â”€â”€ test-planner.ts

â”‚   â”‚   â”œâ”€â”€ story-parser.tsâ”‚   â””â”€â”€ cli/                 # Command-line tools

â”‚   â”‚   â””â”€â”€ story-types.tsâ”‚       â”œâ”€â”€ parse-stories.ts

â”‚   â”œâ”€â”€ planner/             # Test plan generation (Story 20.2)â”‚       â””â”€â”€ plan-tests.ts

â”‚   â”‚   â”œâ”€â”€ test-planner.tsâ”œâ”€â”€ dist/                    # Compiled JavaScript

â”‚   â”‚   â””â”€â”€ test-plan-types.tsâ””â”€â”€ package.json

â”‚   â”œâ”€â”€ generators/          # Test code generators (Stories 20.3-20.5)```

â”‚   â”‚   â”œâ”€â”€ backend/

â”‚   â”‚   â”‚   â”œâ”€â”€ backend-test-generator.ts## Installation

â”‚   â”‚   â”‚   â””â”€â”€ templates/

â”‚   â”‚   â”œâ”€â”€ frontend/```bash

â”‚   â”‚   â”‚   â”œâ”€â”€ frontend-test-generator.tscd test-evidence-framework

â”‚   â”‚   â”‚   â””â”€â”€ templates/npm install

â”‚   â”‚   â””â”€â”€ flow/npm run build

â”‚   â”‚       â”œâ”€â”€ flow-test-generator.ts```

â”‚   â”‚       â””â”€â”€ templates/

â”‚   â”œâ”€â”€ validation/          # Code validation (Story 20.6)## Usage

â”‚   â”‚   â”œâ”€â”€ code-validator.ts

â”‚   â”‚   â””â”€â”€ crystallization-engine.ts### 1. Parse User Stories

â”‚   â”œâ”€â”€ registry/            # Test data management (Story 20.7)

â”‚   â”‚   â”œâ”€â”€ test-data-registry.tsParse all stories from `/user-stories`:

â”‚   â”‚   â””â”€â”€ registry-types.ts

â”‚   â”œâ”€â”€ reportportal/        # ReportPortal integration (Story 20.8)```bash

â”‚   â”‚   â”œâ”€â”€ reportportal-client.tsnpm run parse-stories -- --root ../user-stories

â”‚   â”‚   â””â”€â”€ allure-reportportal-mapper.ts```

â”‚   â”œâ”€â”€ evidence/            # Evidence export (Story 20.9)

â”‚   â”‚   â”œâ”€â”€ reportportal-query-client.ts**With service inference** (automatically detects services from story content):

â”‚   â”‚   â”œâ”€â”€ evidence-exporter.ts

â”‚   â”‚   â””â”€â”€ static-site-generator.ts```bash

â”‚   â”œâ”€â”€ cli/                 # Command-line toolsnpm run parse-stories -- --root ../user-stories --infer

â”‚   â”‚   â”œâ”€â”€ generate-tests.ts```

â”‚   â”‚   â”œâ”€â”€ validate-code.ts

â”‚   â”‚   â”œâ”€â”€ upload-results.tsWith verbose output to see validation errors:

â”‚   â”‚   â””â”€â”€ export-evidence.ts

â”‚   â””â”€â”€ utils/               # Shared utilities```bash

â”‚       â”œâ”€â”€ file-system-utils.tsnpm run parse-stories -- --root ../user-stories --verbose

â”‚       â”œâ”€â”€ logger.ts```

â”‚       â””â”€â”€ template-engine.ts

â”œâ”€â”€ .github/workflows/       # CI/CD workflows (Story 20.10)Save parsed stories to JSON:

â”‚   â”œâ”€â”€ test-evidence.yml

â”‚   â””â”€â”€ deploy-evidence-dashboard.yml```bash

â”œâ”€â”€ docs/                    # Documentation (Story 20.11)npm run parse-stories -- --root ../user-stories --output parsed-stories.json

â”‚   â”œâ”€â”€ DEVELOPER_GUIDE.md```

â”‚   â”œâ”€â”€ QA_GUIDE.md

â”‚   â”œâ”€â”€ TROUBLESHOOTING.md**Output:**

â”‚   â”œâ”€â”€ SERVICES_DECISION_MATRIX.md- Lists all valid stories found

â”‚   â””â”€â”€ WRITING_CRITERIA.md- Reports validation errors (missing sections, invalid services)

â””â”€â”€ package.json- Shows statistics: total stories, by service, by epic

```- **With `--infer`**: Automatically detects services from content when section is missing



## ğŸš€ Quick Start### 2. Generate Test Plans



### PrerequisitesGenerate test plans for all stories:



- Node.js 20+```bash

- npm or yarnnpm run plan-tests -- --root ../user-stories

- Java 21+ (for backend tests)```

- Maven 3.9+ (for backend tests)

- ReportPortal instance (optional, for evidence reporting)**With service inference** (recommended for existing stories without Services Involved section):



### Installation```bash

npm run plan-tests -- --root ../user-stories --infer

```bash```

cd test-evidence-framework

npm installPlan tests for a specific story:

npm run build

``````bash

npm run plan-tests -- --root ../user-stories --story "Story 20.1"

### Generate Tests from a User Story```



```bashPlan tests for all stories involving a service:

# Parse story and generate test plan

npm run generate-tests -- --story ../user-stories/epic_03_cds_trade_capture/story_3_1_create_single_name_cds_trade.md```bash

npm run plan-tests -- --root ../user-stories --service backend --infer

# Generate backend tests```

npm run generate-tests -- --story ../user-stories/epic_03_cds_trade_capture/story_3_1_create_single_name_cds_trade.md --service backend

With verbose output showing planned test details:

# Generate frontend tests

npm run generate-tests -- --story ../user-stories/epic_03_cds_trade_capture/story_3_1_create_single_name_cds_trade.md --service frontend```bash

npm run plan-tests -- --root ../user-stories --verbose --infer

# Generate flow tests (end-to-end)```

npm run generate-tests -- --story ../user-stories/epic_03_cds_trade_capture/story_3_1_create_single_name_cds_trade.md --service flow

```Save test plans to JSON:



### Run Tests Locally```bash

npm run plan-tests -- --root ../user-stories --output test-plans.json --infer

```bash```

# Backend tests (with TestContainers for PostgreSQL)

cd ../backend**Output:**

mvn clean test- Lists all test plans with service coverage

- Shows if flow tests are required (multi-service stories)

# Frontend tests (with Allure)- Estimates recommended test count and complexity

cd ../frontend- Statistics by service

npm run test:unit- **With `--infer`**: Automatically detects services and generates full test plans



# All services with unified reporting## Story Format

cd ..

./scripts/test-unified-local.ps1  # WindowsStories must follow this markdown structure:

./scripts/test-unified-local.sh   # Linux/Mac

``````markdown

# Story X.Y - Title

### Upload Results to ReportPortal

**As a** [actor],  

```bashI want [capability]  

# Set environment variablesSo that [benefit]

export REPORTPORTAL_ENDPOINT=https://your-reportportal.example.com

export REPORTPORTAL_TOKEN=your-api-token## âœ… Acceptance Criteria

export REPORTPORTAL_PROJECT=cds-platform

- Criterion 1

# Upload backend test results- Criterion 2

npm run upload-results -- --service backend --allure-results ../backend/target/allure-results

## ğŸ§ª Test Scenarios

# Upload frontend test results

npm run upload-results -- --service frontend --allure-results ../frontend/allure-results1. Scenario 1

2. Scenario 2

# Upload all services

npm run upload-results -- --all## ğŸ§± Services Involved

```

- frontend

### Export Evidence Dashboard- backend

- gateway

```bash- risk-engine

# Export all stories```

npm run export-evidence -- --output-dir ./evidence-export

**Required sections:**

# Export specific story- `## âœ… Acceptance Criteria` or `## ğŸ§ª Test Scenarios` (at least one)

npm run export-evidence -- --story-id story_3_1 --output-dir ./evidence-export- `## ğŸ§± Services Involved` (with valid service names)



# Export with filters**Valid service names:**

npm run export-evidence -- --services backend,frontend --limit 50 --output-dir ./evidence-export- `frontend` â†’ React (Jest + RTL tests)

```- `backend` â†’ Java Spring Boot (JUnit 5 tests)

- `gateway` â†’ API Gateway (JUnit 5 tests)

## ğŸ“š Documentation- `risk-engine` â†’ Risk calculations (JUnit 5 tests)



### For Developers## Test Type Mapping



- **[Developer Guide](docs/DEVELOPER_GUIDE.md)**: Setup, running tests, ReportPortal integrationThe framework automatically maps services to appropriate test types:

- **[Troubleshooting](docs/TROUBLESHOOTING.md)**: Common issues and solutions

- **[CI/CD Integration](CI-INTEGRATION.md)**: GitHub Actions workflows| Service | Test Types |

- **[Evidence Export](EVIDENCE-EXPORT.md)**: Static dashboard generation|---------|-----------|

| `frontend` | `component`, `unit` |

### For QA Engineers| `backend` | `unit`, `integration`, `api` |

| `gateway` | `unit`, `api` |

- **[QA Guide](docs/QA_GUIDE.md)**: Adding test data, interpreting evidence, managing test suites| `risk-engine` | `unit`, `integration` |

- **[Services Decision Matrix](docs/SERVICES_DECISION_MATRIX.md)**: Determining which services a story affects

**Flow tests:** Stories involving multiple services automatically get `flow` tests added to verify cross-service integration.

### For Story Authors

## Service Inference

- **[Story Template](../user-stories/STORY_TEMPLATE.md)**: Template for writing testable user stories

- **[Writing Criteria Guide](docs/WRITING_CRITERIA.md)**: Best practices for acceptance criteria and test scenariosFor existing stories **without the `## ğŸ§± Services Involved` section**, the framework can automatically infer which services are involved by analyzing story content (title, acceptance criteria, implementation guidance).



## ğŸ”§ Configuration**Enable inference with `--infer` flag:**



### ReportPortal Configuration```bash

npm run parse-stories -- --root ../user-stories --infer

Create `reportportal.json` in the framework root:npm run plan-tests -- --root ../user-stories --infer

```

```json

{**How it works:**

  "endpoint": "https://your-reportportal.example.com",- Analyzes keywords: "ui", "form", "component" â†’ `frontend`

  "token": "your-api-token",- Detects: "api", "endpoint", "controller" â†’ `gateway`

  "project": "cds-platform",- Finds: "service", "repository", "entity" â†’ `backend`

  "launchName": "CDS Platform Tests - Local",- Recognizes: "pricing", "valuation", "risk" â†’ `risk-engine`

  "launchAttributes": [- Applies heuristics: frontend stories usually need gateway + backend

    { "key": "environment", "value": "local" },

    { "key": "framework", "value": "unified-test-evidence" }**See:** [Service Inference Guide](./docs/SERVICE_INFERENCE.md) for details.

  ]

}**Recommendation:** Use `--infer` to bootstrap test planning on existing stories, then add explicit `## ğŸ§± Services Involved` sections for accuracy.

```

## Output Structure

Or use environment variables:

### Parsed Stories JSON

```bash

export REPORTPORTAL_ENDPOINT=https://your-reportportal.example.com```json

export REPORTPORTAL_TOKEN=your-api-token{

export REPORTPORTAL_PROJECT=cds-platform  "parsedAt": "2025-01-20T10:30:00.000Z",

```  "rootPath": "/path/to/user-stories",

  "statistics": {

### Test Data Registry    "totalStories": 96,

    "byService": {

The framework maintains a centralized test data registry at:      "frontend": 25,

      "backend": 45,

```      "gateway": 30,

test-evidence-framework/test-data-registry.json      "risk-engine": 20

```    },

    "multiService": 15,

This registry provides:    "withValidServices": 91,

- **Backend Test Data**: Entities for integration tests (CDSTrade, ReferenceEntity, etc.)    "withMissingServices": 5

- **Frontend Mocks**: Mock data for component and integration tests  },

- **Flow Test Data**: End-to-end test scenarios with multi-service interactions  "stories": [

    {

Add new test data entries via CLI:      "storyId": "Story 3.1",

      "normalizedId": "STORY_3_1",

```bash      "title": "CDS Trade Capture UI",

npm run registry -- add --type backend --category trade --data '{"tradeId":"T001",...}'      "filePath": "/path/to/story_3_1.md",

npm run registry -- add --type frontend --category trade --data '{"tradeId":"T001",...}'      "acceptanceCriteria": ["..."],

```      "testScenarios": ["..."],

      "servicesInvolved": ["frontend", "gateway", "backend"],

## ğŸ¨ Code Generation Templates      "servicesInvolvedStatus": "PRESENT"

    }

### Backend Tests (Java/Spring Boot)  ]

}

Generated tests include:```

- Unit tests with Mockito

- Integration tests with `@SpringBootTest` and TestContainers### Test Plans JSON

- Repository tests with `@DataJpaTest`

- Controller tests with MockMvc```json

- Service tests with comprehensive mocking{

  "generatedAt": "2025-01-20T10:35:00.000Z",

Example:  "statistics": {

    "totalPlans": 96,

```java    "byService": {

@SpringBootTest      "frontend": 25,

@AutoConfigureMockMvc      "backend": 45,

@Testcontainers      "gateway": 30,

@AllureFeature("CDS Trade Capture")      "risk-engine": 20

@AllureStory("Create Single Name CDS Trade")    },

class CDSTradeControllerIntegrationTest {    "flowTestsRequired": 15,

    // Generated test methods based on acceptance criteria    "multiServicePlans": 15

}  },

```  "plans": [

    {

### Frontend Tests (React/TypeScript)      "storyId": "Story 3.1",

      "normalizedId": "STORY_3_1",

Generated tests include:      "title": "CDS Trade Capture UI",

- Component tests with React Testing Library      "plannedServices": ["frontend", "gateway", "backend"],

- Hook tests with `@testing-library/react-hooks`      "plannedTests": [

- Integration tests with mock API responses        {

- Accessibility tests with jest-axe          "service": "frontend",

          "testTypes": ["component", "unit", "flow"],

Example:          "targetPath": "frontend/src/__tests__",

          "acceptanceCriteria": [0, 1, 2],

```typescript          "testScenarios": [0, 1, 2, 3]

describe('CDSTradeForm', () => {        },

  it('should create trade when form submitted with valid data', async () => {        {

    // Generated test based on acceptance criteria          "service": "gateway",

  });          "testTypes": ["unit", "api", "flow"],

});          "targetPath": "gateway/src/test/java",

```          "acceptanceCriteria": [0, 1, 2],

          "testScenarios": [0, 1, 2, 3]

### Flow Tests (End-to-End)        },

        {

Generated tests include:          "service": "backend",

- Multi-service integration scenarios          "testTypes": ["unit", "integration", "api", "flow"],

- REST API orchestration          "targetPath": "backend/src/test/java",

- Database state verification          "acceptanceCriteria": [0, 1, 2],

- Cross-service data consistency checks          "testScenarios": [0, 1, 2, 3]

        }

Example:      ],

      "requiresFlowTests": true,

```typescript      "recommendedTestCount": 8,

describe('CDS Trade Lifecycle', () => {      "complexity": "medium"

  it('should create trade via frontend, persist in backend, and appear in portfolio', async () => {    }

    // Generated flow test spanning frontend â†’ gateway â†’ backend â†’ database  ]

  });}

});```

```

## Development

## ğŸ” Validation & Crystallization

### Build

The framework validates generated tests against story requirements:

```bash

```bashnpm run build

npm run validate-code -- --story ../user-stories/epic_03_cds_trade_capture/story_3_1_create_single_name_cds_trade.md```

```

### Watch mode (auto-rebuild on changes)

Validation checks:

- âœ… All acceptance criteria have corresponding test cases```bash

- âœ… Test scenarios are implementednpm run dev

- âœ… Required services are tested```

- âœ… Test data registry entries exist

- âœ… Allure annotations are correct (feature, story, epic)### Run tests



**Crystallization** locks validated tests to prevent drift:```bash

npm test

```bash```

npm run crystallize -- --story story_3_1

```### Lint



Crystallized tests are marked as "frozen" in the registry and trigger warnings if modified without updating the story.```bash

npm run lint

## ğŸ“Š Evidence Reporting```



### ReportPortal Dashboard## Next Steps



After uploading test results to ReportPortal, view:See [epic_20_test_evidence_framework/README.md](../test-evidence-framework/epic_20_test_evidence_framework/README.md) for implementation roadmap.



- **Launches**: All test executions grouped by launch name**Implemented:**

- **Filters**: Pre-configured filters for each service (backend, frontend, gateway, risk-engine)- âœ… Story 20.1: Story Parser & Topology

- **Widgets**: Custom dashboards showing coverage per story- âœ… Story 20.2: Test Planning by Service

- **Attributes**: Tests tagged with `story`, `service`, `epic`, `acceptanceCriteria`

**Next:**

### Static HTML Dashboard- â³ Story 20.3: Backend Test Generation (JUnit 5)

- â³ Story 20.4: Frontend React Test Generation (Jest + RTL)

Export a static dashboard for stakeholders:- â³ Story 20.7: Test Data & Mock Registry

- â³ Story 20.8: ReportPortal Evidence Integration

```bash- â³ Story 20.9: Evidence Export & Static Dashboard

npm run export-evidence -- --output-dir ./evidence-export- â³ Story 20.10: CI/CD Integration

```

## Links

The dashboard includes:

- **Story Index**: List of all stories with coverage badges- [PRD: Testing Evidence Framework](../unified-testing-stories/TestingPRD.md)

- **Story Details**: Per-story pages with acceptance criteria, test results, and history- [Epic 20: Test Evidence Framework](../test-evidence-framework/epic_20_test_evidence_framework/README.md)

- **Service Tables**: Test execution status per service- [User Stories](../user-stories/)

- **History**: Chronological test execution timeline

Deploy to GitHub Pages:

```bash
# Automated via GitHub Actions (on push to main)
# Or manually:
cd evidence-export
git init
git add .
git commit -m "Evidence dashboard"
git push -f https://github.com/your-org/your-repo.git main:gh-pages
```

View at: `https://your-org.github.io/your-repo/`

## ğŸš¦ CI/CD Integration

The framework includes GitHub Actions workflows:

### Main CI/CD Workflow (`.github/workflows/test-evidence.yml`)

**Pull Requests:**
- Selective test execution (only run tests for changed services)
- ReportPortal upload with PR-specific launch names
- Automated PR comments with test summary and ReportPortal links

**Main Branch:**
- Full test suite execution
- ReportPortal upload with "Main Branch" launch
- Evidence dashboard regeneration and GitHub Pages deployment

### Dashboard Deployment (`.github/workflows/deploy-evidence-dashboard.yml`)

- Manual trigger with optional filters (story ID, services, limit)
- Scheduled daily deployment (00:00 UTC)
- Exports evidence from ReportPortal
- Generates HTML dashboard
- Deploys to GitHub Pages

See **[CI Integration Guide](CI-INTEGRATION.md)** for setup and configuration.

## ğŸ“ˆ Metrics & Reporting

The framework tracks:

- **Story Coverage**: % of acceptance criteria with passing tests
- **Service Coverage**: % of stories tested per service
- **Test Execution History**: Pass/fail trends over time
- **Crystallization Status**: Locked vs unlocked tests

View metrics in:
- ReportPortal widgets
- Static dashboard summary page
- CI/CD workflow summaries

## ğŸ›  Development

### Building the Framework

```bash
npm install
npm run build     # Compile TypeScript to dist/
npm run lint      # Run ESLint
npm run test      # Run unit tests
```

### Adding a New Generator

1. Create generator class in `src/generators/<service>/`
2. Implement `ITestGenerator` interface
3. Add templates in `src/generators/<service>/templates/`
4. Update CLI in `src/cli/generate-tests.ts`
5. Add documentation in `docs/`

### Adding a New CLI Command

1. Create command file in `src/cli/`
2. Add script to `package.json`
3. Update README.md with usage examples
4. Add integration tests

## ğŸ¤ Contributing

1. Write user story using `STORY_TEMPLATE.md`
2. Generate tests: `npm run generate-tests -- --story <path>`
3. Implement functionality in services
4. Run tests locally and validate
5. Submit PR (CI will run tests and comment with results)
6. Merge to main (dashboard updates automatically)

## ğŸ“¦ Project Structure

```
credit-default-swap/
â”œâ”€â”€ backend/                 # Spring Boot backend service
â”‚   â”œâ”€â”€ src/test/           # Generated backend tests
â”‚   â””â”€â”€ target/allure-results/
â”œâ”€â”€ frontend/               # React frontend application
â”‚   â”œâ”€â”€ src/__tests__/      # Generated frontend tests
â”‚   â””â”€â”€ allure-results/
â”œâ”€â”€ gateway/                # API Gateway service
â”‚   â””â”€â”€ src/test/
â”œâ”€â”€ risk-engine/            # Risk calculation service
â”‚   â””â”€â”€ src/test/
â”œâ”€â”€ test-evidence-framework/  # This framework
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ docs/
â”‚   â””â”€â”€ .github/workflows/
â”œâ”€â”€ user-stories/           # Story markdown files
â”‚   â”œâ”€â”€ STORY_TEMPLATE.md
â”‚   â”œâ”€â”€ epic_03_cds_trade_capture/
â”‚   â”œâ”€â”€ epic_04_cds_credit_event_processing/
â”‚   â””â”€â”€ ...
â””â”€â”€ scripts/                # Utility scripts
    â”œâ”€â”€ test-unified-local.ps1
    â””â”€â”€ test-unified-local.sh
```

## ğŸ› Troubleshooting

Common issues:

- **ReportPortal connection failed**: Check `REPORTPORTAL_ENDPOINT`, `REPORTPORTAL_TOKEN`, and network access
- **Tests not appearing in RP**: Verify Allure annotations (`@Feature`, `@Story`, `@Epic`) and result upload
- **Dashboard not deploying**: Check GitHub Pages settings and `deploy-evidence-dashboard.yml` workflow
- **Path filters not working**: Review `detect-changes` job output and path patterns in `test-evidence.yml`

See **[Reference Guide](docs/REFERENCE.md)** for comprehensive troubleshooting.

## ğŸ“„ License

MIT License - see LICENSE file for details

## ï¿½ Documentation

- **[Getting Started](docs/GETTING_STARTED.md)** - Quick start guide (5 min install, 10 min first tests)
- **[User Guide](docs/USER_GUIDE.md)** - Comprehensive developer and QA guide
- **[Integration](docs/INTEGRATION.md)** - CI/CD, ReportPortal, and evidence dashboard setup
- **[Reference](docs/REFERENCE.md)** - Troubleshooting, service selection, and writing best practices
- **[Story Template](../user-stories/STORY_TEMPLATE.md)** - Template for writing new stories

**External Resources:**
- [ReportPortal Documentation](https://reportportal.io/docs)
- [Allure Documentation](https://docs.qameta.io/allure/)

---

**Version**: 1.0.0  
**Epic**: 20 - Test Evidence Framework  
**Last Updated**: November 2025
